#
#  shared configuration for all cde datasets
#

seed: 5012022

# used for info only
source name: CodEx
source graph: Wikidata

# all csv files are saved using this character
separator: '|'

# upstream text data csv containing:
# page, eid, entity, mention, start, end
# loader are defined in irt2/sampling.py
# paths are relative to root path
#   - used by ipynb/create-text.ipynb
source matches: data/source/matches/irt.cde/irt.cde.matches-full.csv

# database containing the matches for sampling
#   - used by ipynb/create-text.ipynb
source pages: data/source/matches/db/matches-v6-codex.db

# source pages are transformed in a sentence based data format for
# later selection based on the concrete splits
#   - depends on source matches and source pages
#   - created by ipynb/create-text.ipynb
#   - used by ipynb/create.ipynb
source sentences: data/source/sentences/matches-v6-codex.db.gz

# spacy model used for sentence boundary detection
spacy model: en_core_web_lg

# remove all mentions which have less than X matches assigned
prune mentions: 5

# upstream graph data
# loader are defined in irt2/graph.py
# paths are relative to root path
graph name: 'CodEx-M'
graph loader: codex
graph loader args:
  - lib/codex/data/triples/codex-m/train.txt
  - lib/codex/data/triples/codex-m/valid.txt
  - lib/codex/data/triples/codex-m/test.txt
graph loader kwargs:
  f_ent2id: lib/codex/data/entities/en/entities.json
  f_rel2id: lib/codex/data/relations/en/relations.json
