{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82c2827-6a48-4591-a130-238ef9f48392",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KGC Control Experiments\n",
    "\n",
    "We run two control experiments to check correctness of metric calculation,\n",
    "and get a upper performance boundary for chat based llms which propose mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2365c8cb-1c9b-4df9-a990-fcd7678c900b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import irt2\n",
    "\n",
    "p_data = irt2.ENV.DIR.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efddd0f9-fc61-42ec-a520-815762bb79fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from irt2.types import Split, Task, Sample, MID, RID, VID\n",
    "from irt2.dataset import IRT2\n",
    "from irt2.evaluation import Predictions\n",
    "\n",
    "import random\n",
    "from typing import Iterable, Literal\n",
    "\n",
    "\n",
    "Tasks = dict[tuple[MID, RID], set[VID]]\n",
    "\n",
    "\n",
    "def true_vids(tasks: Tasks, ds: IRT2, **_) -> Predictions:\n",
    "    \"\"\"This model cheats and always answers always correctly.\"\"\"\n",
    "    for (mid, rid), vids in tasks.items():\n",
    "        yield (mid, rid), ((vid, 1) for vid in vids)\n",
    "\n",
    "def true_mentions(\n",
    "    tasks: Tasks,\n",
    "    ds: IRT2,\n",
    "    split: Literal['validation', 'test'],\n",
    "    **_,\n",
    ") -> Predictions:\n",
    "    \"\"\"This model cheats and knows the correct mentions.\"\"\"\n",
    "    splits = (Split.train, Split.valid)\n",
    "    if split == 'test':\n",
    "        splits += (Split.test, )\n",
    "\n",
    "    ids = ds.idmap\n",
    "    for (mid, rid), gt_vids in tasks.items():\n",
    "        mentions = {\n",
    "            ids.mid2str[mid]\n",
    "            for mids in map(ids.vid2mids.get, gt_vids)\n",
    "            for mid in mids\n",
    "        }\n",
    "\n",
    "        pr_vids = ds.find_by_mention(\n",
    "            *mentions,\n",
    "            splits=splits,\n",
    "        )\n",
    "\n",
    "        yield (mid, rid), ((vid, 1) for vid in pr_vids)\n",
    "\n",
    "\n",
    "def random_guessing(\n",
    "    tasks: Tasks,\n",
    "    ds: IRT2,\n",
    "    split: Literal['validation', 'test'],\n",
    "    seed: int,\n",
    "    **_,\n",
    ") -> Predictions:\n",
    "    \"\"\"This model is just guessing randomly.\"\"\"\n",
    "    rng = random.Random()\n",
    "    rng.seed(seed)\n",
    "\n",
    "    ids = ds.idmap\n",
    "    candidates = ids.split2vids[Split.train] | ids.split2vids[Split.valid]\n",
    "    if split == 'test':\n",
    "        candidates |= ids.split2vids[Split.test]\n",
    "\n",
    "    perm = list(candidates)\n",
    "    for (mid, rid), vids in tasks.items():\n",
    "        yield (mid, rid), ((vid, rng.random()) for vid in rng.sample(perm, k=100))\n",
    "\n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    'true-vertices': true_vids,\n",
    "    'true-mentions': true_mentions,\n",
    "    'random-guessing': random_guessing,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92ebf34-04b8-44b4-bd0b-ef219153fec5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from irt2 import evaluation\n",
    "from ktz.collections import dflat\n",
    "\n",
    "import yaml\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def flatten(report: dict):\n",
    "    before = dict(\n",
    "        dataset=report['dataset'],\n",
    "        model=report['model'],\n",
    "        date=report['date'],\n",
    "        split=report['split'],\n",
    "    )\n",
    "\n",
    "    metrics = dflat(report['metrics'], sep=' ')\n",
    "    metrics = dict(sorted(metrics.items()))\n",
    "\n",
    "    return before | metrics\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    ds: IRT2,\n",
    "    name: str,\n",
    "    split: str,\n",
    "    head_predictions: Predictions,\n",
    "    tail_predictions: Predictions,\n",
    "):\n",
    "    metrics = evaluation.evaluate(\n",
    "        ds=ds,\n",
    "        task='kgc',\n",
    "        split=split,\n",
    "        head_predictions=head_predictions,\n",
    "        tail_predictions=tail_predictions,\n",
    "    )\n",
    "\n",
    "    return evaluation.create_report(\n",
    "        metrics,\n",
    "        ds,\n",
    "        task='kgc',\n",
    "        split=split,\n",
    "        model=name,\n",
    "        filenames=dict(notebook='ipynb/control-experiments.ipynb'),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def run(\n",
    "    ds: IRT2,\n",
    "    name: str,\n",
    "    model: Callable,\n",
    "    split: str,\n",
    "    seed: int,\n",
    "):\n",
    "    predictor = partial(\n",
    "        model,\n",
    "        ds=ds,\n",
    "        split=split,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    assert split == 'validation' or split == 'test'\n",
    "\n",
    "    if split == 'validation':\n",
    "        head_predictions = predictor(ds.open_kgc_val_heads)\n",
    "        tail_predictions = predictor(ds.open_kgc_val_tails)\n",
    "\n",
    "    if split == 'test':\n",
    "        head_predictions = predictor(ds.open_kgc_test_heads)\n",
    "        tail_predictions = predictor(ds.open_kgc_test_tails)\n",
    "\n",
    "\n",
    "    report = evaluate(\n",
    "        ds=ds,\n",
    "        name=name,\n",
    "        split=split,\n",
    "        head_predictions=head_predictions,\n",
    "        tail_predictions=tail_predictions,\n",
    "    )\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a558169f-db1d-45a2-a01e-4bdda41bf0dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write results to /home/felix/Complex/dkg/irt2/data/evaluation/control-experiments-31189.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP/WIKIDATA5M: 4818582 vertices | 822 relations | 11804166 mentions\n",
      "  validation\n",
      "    - seed=31189 percentage=0.09 520 head and 579 tail tasks = 1099\n",
      "    - model:  true-mentions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test\n",
      "    - seed=31189 percentage=0.08 471 head and 529 tail tasks = 1000\n",
      "    - model:  true-mentions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from ktz.collections import dconv\n",
    "from irt2.loader import LOADER\n",
    "\n",
    "\n",
    "def _run_all(datasets, models, splits, seed: int):\n",
    "    for dataset_config in datasets:\n",
    "        ds = LOADER[dataset_config['loader']](dataset_config['path'])\n",
    "        print(str(ds))\n",
    "\n",
    "        for split in splits:\n",
    "            percentage = None\n",
    "            # percentage = dataset_config['percentage'][split]\n",
    "            sub_ds = ds.tasks_subsample_kgc(percentage, seed=seed)\n",
    "\n",
    "            if split == 'validation':\n",
    "                n_heads = len(sub_ds.open_kgc_val_heads)\n",
    "                n_tails = len(sub_ds.open_kgc_val_tails)\n",
    "\n",
    "            if split == 'test':\n",
    "                n_heads = len(sub_ds.open_kgc_test_heads)\n",
    "                n_tails = len(sub_ds.open_kgc_test_tails)\n",
    "\n",
    "            print(\n",
    "                '  ' + split,\n",
    "                f'{seed=} {percentage=}'\n",
    "                f' {n_heads} head and {n_tails} tail tasks'\n",
    "                f' = {n_heads + n_tails}',\n",
    "                sep='\\n    - ',\n",
    "            )\n",
    "\n",
    "            meta = {\n",
    "                'percentage': percentage,\n",
    "                'total tasks': n_heads + n_tails,\n",
    "                'head tasks': n_heads,\n",
    "                'tail tasks': n_tails,\n",
    "            }\n",
    "\n",
    "            # print(', '.join(map(str, sub_ds.table_row)))\n",
    "            for model in models:\n",
    "                print('    - model: ', model)\n",
    "                report = run(sub_ds, model, MODELS[model], split, seed)\n",
    "                yield meta | flatten(report)\n",
    "\n",
    "\n",
    "def run_all(out, datasets, models, splits, seed: int):\n",
    "    out.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(f'write results to {out}')\n",
    "    with out.open(mode='w') as fd:\n",
    "        writer = None\n",
    "\n",
    "        for flat in _run_all(datasets, models, splits, seed):\n",
    "            if writer is None:\n",
    "                header = ['seed'] + list(flat.keys())\n",
    "\n",
    "                writer = csv.DictWriter(fd, fieldnames=header)\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerow(flat | {'seed': seed})\n",
    "\n",
    "\n",
    "\n",
    "all_config = {\n",
    "    'datasets': [\n",
    "        # {\n",
    "        #     'path': p_data / 'irt2' / 'irt2-cde-tiny',\n",
    "        #     'loader': 'irt2',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.17,\n",
    "        #         'test': 0.02,\n",
    "        #     },\n",
    "        # },\n",
    "        # {\n",
    "        #     'path': p_data / 'irt2' / 'irt2-cde-small',\n",
    "        #     'loader': 'irt2',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.08,\n",
    "        #         'test': 0.02,\n",
    "        #     },\n",
    "        # },\n",
    "        # {\n",
    "        #     'path': p_data / 'irt2' / 'irt2-cde-medium',\n",
    "        #     'loader': 'irt2',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.04,\n",
    "        #         'test': 0.01,\n",
    "        #     },\n",
    "        # },\n",
    "        # {\n",
    "        #     'path': p_data / 'irt2' / 'irt2-cde-large',\n",
    "        #     'loader': 'irt2',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.05,\n",
    "        #         'test': 0.02,\n",
    "        #     },\n",
    "        # },\n",
    "        # {\n",
    "        #     'path': p_data/ 'blp' / 'WN18RR',\n",
    "        #     'loader': 'blp/wn18rr',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.06,\n",
    "        #         'test': 0.06,\n",
    "        #     },\n",
    "        # },\n",
    "        # {\n",
    "        #     'path': p_data/ 'blp' / 'FB15k-237',\n",
    "        #     'loader': 'blp/fb15k237',\n",
    "        #     'percentage': {\n",
    "        #         'validation': 0.03,\n",
    "        #         'test': 0.03,\n",
    "        #     },\n",
    "        # },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'Wikidata5M',\n",
    "            'loader': 'blp/wikidata5m',\n",
    "            'percentage': {\n",
    "                'validation': 0.09,\n",
    "                'test': 0.08,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    'models': [\n",
    "        # 'true-vertices',\n",
    "        'true-mentions',\n",
    "        # 'random-guessing',\n",
    "    ],\n",
    "    'splits': [\n",
    "        'validation',\n",
    "        'test',\n",
    "    ],\n",
    "    'seed': 31189,\n",
    "}\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    root = p_data / \"evaluation\"\n",
    "    ffmt = \"control-experiments-{seed}.{suffix}\"\n",
    "    fcsv = ffmt.format(suffix='csv', **config)\n",
    "    run_all(out=root / fcsv, **config)\n",
    "\n",
    "\n",
    "main(all_config)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fd324-5b53-4363-ac4e-541943d6bbf1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "subsample_config = {\n",
    "    'datasets': [\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-tiny',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-small',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-medium',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-large',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'WN18RR',\n",
    "            'loader': 'blp/wn18rr',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'FB15k-237',\n",
    "            'loader': 'blp/fb15k237',\n",
    "        },\n",
    "        # {\n",
    "        #     'path': p_data/ 'blp' / 'Wikidata5M',\n",
    "        #     'loader': 'blp/wikidata5m',\n",
    "        # },\n",
    "    ],\n",
    "    'seed': 31189,\n",
    "}\n",
    "\n",
    "\n",
    "def run_subsampling(out, datasets, seed, percentages: Iterable[float]):\n",
    "    out.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(f'write results to {out}')\n",
    "    with out.open(mode='w') as fd:\n",
    "        writer = None\n",
    "\n",
    "        for dataset_config in datasets:\n",
    "            ds = LOADER[dataset_config['loader']](dataset_config['path'])\n",
    "            print(str(ds))\n",
    "\n",
    "            for percentage in percentages:\n",
    "                print(f'  - {int(percentage * 100):3d}%', f'{seed=}')\n",
    "                sub_ds = ds.tasks_subsample_kgc(percentage=percentage, seed=seed)\n",
    "\n",
    "                report = run(\n",
    "                    sub_ds,\n",
    "                    name='true-mentions',\n",
    "                    model=MODELS['true-mentions'],\n",
    "                    split='validation',\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                flat = flatten(report)\n",
    "\n",
    "                if writer is None:\n",
    "                    header = ['percentage', 'head tasks', 'tail tasks', 'seed'] + list(flat.keys())\n",
    "                    writer = csv.DictWriter(fd, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "\n",
    "                writer.writerow(flat | {\n",
    "                    'percentage': percentage,\n",
    "                    'head tasks': len(sub_ds.open_kgc_val_heads),\n",
    "                    'tail tasks': len(sub_ds.open_kgc_val_tails),\n",
    "                    'seed': seed\n",
    "                })\n",
    "\n",
    "\n",
    "def subsample_experiments(config, ks: Iterable[int]):\n",
    "    root = p_data / \"evaluation\"\n",
    "    ffmt = \"subsample-experiments-{seed}.{suffix}\"\n",
    "\n",
    "    fcsv = ffmt.format(\n",
    "        seed=config['seed'],\n",
    "        suffix='csv',\n",
    "    )\n",
    "\n",
    "    run_subsampling(\n",
    "        out=root / fcsv,\n",
    "        percentages=[0.01, 0.025] + [x/100 for x in range(5, 101, 5)],\n",
    "        **config,\n",
    "    )\n",
    "\n",
    "\n",
    "subsample_experiments(subsample_config, ks=[50, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "name": "control-experiments.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
