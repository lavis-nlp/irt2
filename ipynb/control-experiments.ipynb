{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82c2827-6a48-4591-a130-238ef9f48392",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KGC Control Experiments\n",
    "\n",
    "We run two control experiments to check correctness of metric calculation,\n",
    "and get a upper performance boundary for chat based llms which propose mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2365c8cb-1c9b-4df9-a990-fcd7678c900b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import irt2\n",
    "\n",
    "p_data = irt2.ENV.DIR.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efddd0f9-fc61-42ec-a520-815762bb79fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from irt2.types import Split, Task, Sample, MID, RID, VID\n",
    "from irt2.dataset import IRT2\n",
    "from irt2.evaluation import Predictions\n",
    "\n",
    "import random\n",
    "from typing import Iterable, Literal\n",
    "\n",
    "\n",
    "Tasks = dict[tuple[MID, RID], set[VID]]\n",
    "\n",
    "\n",
    "def true_vids(tasks: Tasks, ds: IRT2, **_) -> Predictions:\n",
    "    \"\"\"This model cheats and always answers always correctly.\"\"\"\n",
    "    for (mid, rid), vids in tasks.items():\n",
    "        yield (mid, rid), ((vid, 1) for vid in vids)\n",
    "\n",
    "def true_mentions(\n",
    "    tasks: Tasks,\n",
    "    ds: IRT2,\n",
    "    split: Literal['validation', 'test'],\n",
    "    **_,\n",
    ") -> Predictions:\n",
    "    \"\"\"This model cheats and knows the correct mentions.\"\"\"\n",
    "    splits = (Split.train, Split.valid)\n",
    "    if split == 'test':\n",
    "        splits += (Split.test, )\n",
    "\n",
    "    ids = ds.idmap\n",
    "    for (mid, rid), gt_vids in tasks.items():\n",
    "        mentions = {\n",
    "            ids.mid2str[mid]\n",
    "            for mids in map(ids.vid2mids.get, gt_vids)\n",
    "            for mid in mids\n",
    "        }\n",
    "\n",
    "        pr_vids = ds.find_by_mention(\n",
    "            *mentions,\n",
    "            splits=splits,\n",
    "        )\n",
    "\n",
    "        yield (mid, rid), ((vid, 1) for vid in pr_vids)\n",
    "\n",
    "\n",
    "def random_guessing(\n",
    "    tasks: Tasks,\n",
    "    ds: IRT2,\n",
    "    split: Literal['validation', 'test'],\n",
    "    seed: int,\n",
    "    **_,\n",
    ") -> Predictions:\n",
    "    \"\"\"This model is just guessing randomly.\"\"\"\n",
    "    rng = random.Random()\n",
    "    rng.seed(seed)\n",
    "\n",
    "    ids = ds.idmap\n",
    "    candidates = ids.split2vids[Split.train] | ids.split2vids[Split.valid]\n",
    "    if split == 'test':\n",
    "        candidates |= ids.split2vids[Split.test]\n",
    "\n",
    "    perm = list(candidates)\n",
    "    for (mid, rid), vids in tasks.items():\n",
    "        yield (mid, rid), ((vid, rng.random()) for vid in rng.sample(perm, k=100))\n",
    "\n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    'true-vertices': true_vids,\n",
    "    'true-mentions': true_mentions,\n",
    "    'random-guessing': random_guessing,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92ebf34-04b8-44b4-bd0b-ef219153fec5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from irt2 import evaluation\n",
    "from ktz.collections import dflat\n",
    "\n",
    "import yaml\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def flatten(report: dict):\n",
    "    before = dict(\n",
    "        dataset=report['dataset'],\n",
    "        model=report['model'],\n",
    "        date=report['date'],\n",
    "        split=report['split'],\n",
    "    )\n",
    "\n",
    "    metrics = dflat(report['metrics'], sep=' ')\n",
    "    metrics = dict(sorted(metrics.items()))\n",
    "\n",
    "    return before | metrics\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    ds: IRT2,\n",
    "    name: str,\n",
    "    split: str,\n",
    "    head_predictions: Predictions,\n",
    "    tail_predictions: Predictions,\n",
    "):\n",
    "    metrics = evaluation.evaluate(\n",
    "        ds=ds,\n",
    "        task='kgc',\n",
    "        split=split,\n",
    "        head_predictions=head_predictions,\n",
    "        tail_predictions=tail_predictions,\n",
    "    )\n",
    "\n",
    "    return evaluation.create_report(\n",
    "        metrics,\n",
    "        ds,\n",
    "        task='kgc',\n",
    "        split=split,\n",
    "        model=name,\n",
    "        filenames=dict(notebook='ipynb/control-experiments.ipynb'),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def run(\n",
    "    ds: IRT2,\n",
    "    name: str,\n",
    "    model: Callable,\n",
    "    split: str,\n",
    "    seed: int,\n",
    "):\n",
    "    predictor = partial(\n",
    "        model,\n",
    "        ds=ds,\n",
    "        split=split,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    assert split == 'validation' or split == 'test'\n",
    "\n",
    "    if split == 'validation':\n",
    "        head_predictions = predictor(ds.open_kgc_val_heads)\n",
    "        tail_predictions = predictor(ds.open_kgc_val_tails)\n",
    "\n",
    "    if split == 'test':\n",
    "        head_predictions = predictor(ds.open_kgc_test_heads)\n",
    "        tail_predictions = predictor(ds.open_kgc_test_tails)\n",
    "\n",
    "\n",
    "    report = evaluate(\n",
    "        ds=ds,\n",
    "        name=name,\n",
    "        split=split,\n",
    "        head_predictions=head_predictions,\n",
    "        tail_predictions=tail_predictions,\n",
    "    )\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a558169f-db1d-45a2-a01e-4bdda41bf0dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write results to /home/felix/Complex/dkg/irt2/data/evaluation/control-experiments-1000-31189.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-T: 12389 vertices | 5 relations | 23894 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-S: 14207 vertices | 12 relations | 28582 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n",
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-M: 15020 vertices | 45 relations | 32666 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n",
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-L: 15020 vertices | 45 relations | 32666 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n",
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP/WN18RR: 40943 vertices | 11 relations | 40943 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n",
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP/FB15K237: 14951 vertices | 237 relations | 14951 mentions at_most=1000 seed=31189\n",
      "  -  true-vertices validation\n",
      "  -  true-vertices test\n",
      "  -  true-mentions validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  true-mentions test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  random-guessing validation\n",
      "  -  random-guessing test\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from ktz.collections import dconv\n",
    "from irt2.loader import LOADER\n",
    "\n",
    "\n",
    "def _run_all(datasets, models, splits, seed, at_most = None):\n",
    "    for dataset_config in datasets:\n",
    "        ds = LOADER[dataset_config['loader']](dataset_config['path'])\n",
    "        ds = ds.tasks_subsample(to=at_most, seed=seed)\n",
    "\n",
    "        print(str(ds), f'{at_most=}', f'{seed=}')\n",
    "        # print(', '.join(map(str, ds.table_row)))\n",
    "\n",
    "        for model in models:\n",
    "            for split in splits:\n",
    "                print('  - ', model, split)\n",
    "\n",
    "                report = run(ds, model, MODELS[model], split, seed)\n",
    "                yield flatten(report)\n",
    "\n",
    "\n",
    "def run_all(out, datasets, models, splits, seed, at_most = None):\n",
    "    out.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(f'write results to {out}')\n",
    "    with out.open(mode='w') as fd:\n",
    "        writer = None\n",
    "\n",
    "        for flat in _run_all(datasets, models, splits, seed, at_most):\n",
    "            if writer is None:\n",
    "                header = ['at most', 'seed'] + list(flat.keys())\n",
    "                writer = csv.DictWriter(fd, fieldnames=header)\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerow(flat | {'at most': at_most, 'seed': seed})\n",
    "\n",
    "\n",
    "\n",
    "all_config = {\n",
    "    'datasets': [\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-tiny',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-small',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-medium',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-large',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        # {   'path': p_data/ 'blp' / 'umls',\n",
    "        #     'loader': 'blp/umls',\n",
    "        # },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'WN18RR',\n",
    "            'loader': 'blp/wn18rr',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'FB15k-237',\n",
    "            'loader': 'blp/fb15k237',\n",
    "        },\n",
    "        # {\n",
    "        #     'path': p_data/ 'blp' / 'Wikidata5M',\n",
    "        #     'loader': 'blp/wikidata5m',\n",
    "        # },\n",
    "    ],\n",
    "    'models': [\n",
    "        # 'true-vertices',\n",
    "        'true-mentions',\n",
    "        # 'random-guessing',\n",
    "    ],\n",
    "    'splits': [\n",
    "        'validation',\n",
    "        # 'test',\n",
    "    ],\n",
    "    'at_most': 1000,\n",
    "    'seed': 31189,\n",
    "}\n",
    "\n",
    "def main(config):\n",
    "    root = p_data / \"evaluation\"\n",
    "    ffmt = \"control-experiments-{at_most}-{seed}.{suffix}\"\n",
    "\n",
    "    fcsv = ffmt.format(\n",
    "        at_most=config['at_most'],\n",
    "        seed=config['seed'],\n",
    "        suffix='csv',\n",
    "    )\n",
    "\n",
    "    run_all(\n",
    "        out=root / fcsv,\n",
    "        **config,\n",
    "    )\n",
    "\n",
    "\n",
    "main(all_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1fd324-5b53-4363-ac4e-541943d6bbf1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write results to /home/felix/Complex/dkg/irt2/data/evaluation/subsample-experiments-31189.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-T: 12389 vertices | 5 relations | 23894 mentions\n",
      "  -   1% = 58 seed=31189\n",
      "  -   2% = 147 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-S: 14207 vertices | 12 relations | 28582 mentions\n",
      "  -   1% = 141 seed=31189\n",
      "  -   2% = 354 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-M: 15020 vertices | 45 relations | 32666 mentions\n",
      "  -   1% = 269 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -   2% = 673 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT2/CDE-L: 15020 vertices | 45 relations | 32666 mentions\n",
      "  -   1% = 213 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -   2% = 534 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP/WN18RR: 40943 vertices | 11 relations | 40943 mentions\n",
      "  -   1% = 175 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -   2% = 439 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP/FB15K237: 14951 vertices | 237 relations | 14951 mentions\n",
      "  -   1% = 342 seed=31189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -   2% = 855 seed=31189\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "subsample_config = {\n",
    "    'datasets': [\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-tiny',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-small',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-medium',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data / 'irt2' / 'irt2-cde-large',\n",
    "            'loader': 'irt2',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'WN18RR',\n",
    "            'loader': 'blp/wn18rr',\n",
    "        },\n",
    "        {\n",
    "            'path': p_data/ 'blp' / 'FB15k-237',\n",
    "            'loader': 'blp/fb15k237',\n",
    "        },\n",
    "        # {\n",
    "        #     'path': p_data/ 'blp' / 'Wikidata5M',\n",
    "        #     'loader': 'blp/wikidata5m',\n",
    "        # },\n",
    "    ],\n",
    "    'seed': 31189,\n",
    "}\n",
    "\n",
    "\n",
    "def run_subsampling(out, datasets, seed, percentages: Iterable[float]):\n",
    "    out.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(f'write results to {out}')\n",
    "    with out.open(mode='w') as fd:\n",
    "        writer = None\n",
    "\n",
    "        for dataset_config in datasets:\n",
    "            ds = LOADER[dataset_config['loader']](dataset_config['path'])\n",
    "            print(str(ds))\n",
    "\n",
    "            for percentage in percentages:\n",
    "                at_most = len(ds.open_kgc_val_heads) + len(ds.open_kgc_val_tails)\n",
    "                at_most = int(percentage * at_most)\n",
    "\n",
    "                print(f'  - {int(percentage * 100):3d}% = {at_most}', f'{seed=}')\n",
    "                sub_ds = ds.tasks_subsample(to=at_most, seed=seed)\n",
    "\n",
    "                report = run(\n",
    "                    sub_ds,\n",
    "                    name='true-mentions',\n",
    "                    model=MODELS['true-mentions'],\n",
    "                    split='validation',\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                flat = flatten(report)\n",
    "\n",
    "                if writer is None:\n",
    "                    header = ['percentage', 'at most', 'seed'] + list(flat.keys())\n",
    "                    writer = csv.DictWriter(fd, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "\n",
    "                writer.writerow(flat | {'percentage': percentage, 'at most': at_most, 'seed': seed})\n",
    "\n",
    "\n",
    "def subsample_experiments(config, ks: Iterable[int]):\n",
    "    root = p_data / \"evaluation\"\n",
    "    ffmt = \"subsample-experiments-{seed}.{suffix}\"\n",
    "\n",
    "    fcsv = ffmt.format(\n",
    "        seed=config['seed'],\n",
    "        suffix='csv',\n",
    "    )\n",
    "\n",
    "    run_subsampling(\n",
    "        out=root / fcsv,\n",
    "        percentages=[0.01, 0.025],\n",
    "        # percentages=[x/100 for x in range(5, 101, 5)],\n",
    "        **config,\n",
    "    )\n",
    "\n",
    "\n",
    "subsample_experiments(subsample_config, ks=[50, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "name": "control-experiments.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
