{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559b00e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# IRT2 - Inductive Reasoning with Text\n",
    "\n",
    "This notebook describes how to load the IRT2 dataset. \n",
    "Some of the properties are looked at in detail to offer insights into the datamodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a9e23",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96d54e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import irt2\n",
    "from irt2.dataset import IRT2\n",
    "from irt2.dataset import MID\n",
    "\n",
    "import textwrap\n",
    "from itertools import islice\n",
    "from tabulate import tabulate\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from typing import Generator\n",
    "\n",
    "#  folder convention:\n",
    "#     data/irt2/<graph>/<size>\n",
    "#  where\n",
    "#     graph = cde|fb\n",
    "#     size  = tiny|small|medium|large (abbreviated: T|S|M|L)\n",
    "#  for example:\n",
    "#     path = 'data/irt2/cde/small'\n",
    "\n",
    "data = IRT2.from_dir(path=irt2.ENV.DIR.DATA / 'irt2' / 'cde' / 'small')\n",
    "print(str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949b3d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it iterates all text contexts and this might take while...\n",
    "# repeated calls are cheap: return value is cached\n",
    "print(data.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efa0a5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Further information is given in the configuration file\n",
    "# which was used for dataset creation. For an explanation of\n",
    "# the different options, see the original files in /conf.\n",
    "import yaml\n",
    "\n",
    "print(yaml.dump(data.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95214fc8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show example vertices and relations\n",
    "\n",
    "print('\\nvertices:')\n",
    "print(f'    vid name')\n",
    "for vid, name in islice(data.vertices.items(), 10):\n",
    "    print(f'{vid:7d} {name}')\n",
    "\n",
    "print('\\nrelations:')\n",
    "print(f'    rid name')\n",
    "for rid, name in islice(data.relations.items(), 10):\n",
    "    print(f'{rid:7d} {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bdd4d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show example closed-world triples\n",
    "\n",
    "print(tabulate(\n",
    "    [\n",
    "        (h, data.vertices[h], r, data.relations[r], t, data.vertices[t])\n",
    "        for h, t, r in islice(data.closed_triples, 20)\n",
    "    ],\n",
    "    headers=('VID', 'head', 'RID', 'relation', 'VID', 'tail')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215b2eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this showcases how to access text contexts\n",
    "\n",
    "def count_contexts(contexts: Generator, n: int = None):\n",
    "\n",
    "    counts = dict(total=0, mids=Counter(), origins=Counter())\n",
    "\n",
    "    for context in islice(contexts, n):\n",
    "\n",
    "        assert context.mid in data.mentions\n",
    "        assert context.mention in context.data\n",
    "\n",
    "        counts['total'] += 1\n",
    "        counts['mids'][context.mid] += 1\n",
    "        counts['origins'][context.origin] += 1\n",
    "\n",
    "    print(f'  read {counts[\"total\"]} relevant contexts')\n",
    "    print(f'  for {len(counts[\"mids\"])} mentions from {len(counts[\"origins\"])} origins')\n",
    "\n",
    "    return counts\n",
    "\n",
    "# Contexts are retrieved using a context manager which handles\n",
    "# opening/closing files appropriately. The managed object is\n",
    "# a generator yielding irt2.dataset.Context objects.\n",
    "\n",
    "n = 10_000\n",
    "\n",
    "with data.closed_contexts() as contexts:\n",
    "    print('\\ncounting closed-world (training) contexts')\n",
    "    ctx_counts_closed = count_contexts(contexts, n=n)\n",
    "\n",
    "with data.open_contexts_validation() as contexts:\n",
    "    print('\\ncounting open-world (validation) contexts')\n",
    "    ctx_counts_open_val = count_contexts(contexts, n=n)\n",
    "\n",
    "with data.open_contexts_test() as contexts:\n",
    "    print('\\ncounting open-world (test) contexts')\n",
    "    ctx_counts_open_test = count_contexts(contexts, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b2a65",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show some mentions\n",
    "\n",
    "print('\\nclosed-world (training) ' + '-' * 20)\n",
    "for vid, mids in islice(data.closed_mentions.items(), 30, 35):\n",
    "    print(f'\\n  {len(mids)} mentions of {data.vertices[vid]} ({vid=})')\n",
    "    for mid in mids:\n",
    "        mention = data.mentions[mid]\n",
    "        print(f'    {mid=} {mention} ({ctx_counts_closed[\"mids\"][mid]} matches)')\n",
    "\n",
    "print('\\nopen-world (validation) ' + '-' * 20)\n",
    "# open-world mentions\n",
    "for vid, mids in islice(data.open_mentions_val.items(), 30, 35):\n",
    "    print(f'\\n  {len(mids)} mentions of {data.vertices[vid]} ({vid=})')\n",
    "    for mid in mids:\n",
    "        mention = data.mentions[mid]\n",
    "        print(f'    {mid=} {mention} ({ctx_counts_open_val[\"mids\"][mid]} matches)')\n",
    "\n",
    "print('\\nopen-world (test) ' + '-' * 20)\n",
    "# open-world mentions\n",
    "for vid, mids in islice(data.open_mentions_test.items(), 30, 35):\n",
    "    print(f'\\n  {len(mids)} mentions of {data.vertices[vid]} ({vid=})')\n",
    "    for mid in mids:\n",
    "        mention = data.mentions[mid]\n",
    "        print(f'    {mid=} {mention} ({ctx_counts_open_test[\"mids\"][mid]} matches)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b0c73",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some examples for the head and tail tasks\n",
    "# also doing a reverse-lookup for head vertices\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "mid2vid = {\n",
    "    mid: vid\n",
    "    for vid, mids in chain(\n",
    "            data.closed_mentions.items(),\n",
    "            data.open_mentions_val.items(),\n",
    "            data.open_mentions_test.items(),\n",
    "    )\n",
    "    for mid in mids\n",
    "}\n",
    "\n",
    "N = 5\n",
    "\n",
    "print('\\nHEAD TASK ' + '-' * 20)\n",
    "for (mid, rid), vids in islice(data.open_task_val_heads.items(), 10):\n",
    "    print(f'\\n\"{data.mentions[mid]}\" ({data.vertices[mid2vid[mid]]}) {data.relations[rid]} ?')\n",
    "    for vid in list(vids)[:N]:\n",
    "        print(f'  answer: {data.vertices[vid]}')\n",
    "\n",
    "    if len(vids) > N:\n",
    "        print(f'  (+{len(vids) - N} more)')\n",
    "\n",
    "print('\\nTAIL TASK ' + '-' * 20)\n",
    "for (mid, rid), vids in islice(data.open_task_val_tails.items(), 10):\n",
    "    print(f'\\n? {data.relations[rid]} \"{data.mentions[mid]}\" ({data.vertices[mid2vid[mid]]})')\n",
    "    for vid in list(vids)[:5]:\n",
    "        print(f'  answer: {data.vertices[vid]}')\n",
    "\n",
    "    if len(vids) > N:\n",
    "        print(f'  (+{len(vids) - N} more)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ae48f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print some example texts\n",
    "\n",
    "texts = defaultdict(set)\n",
    "with data.closed_contexts() as contexts:\n",
    "    for ctx in islice(contexts, 1000):\n",
    "        texts[ctx.mid].add(ctx)\n",
    "\n",
    "    texts = dict(texts)\n",
    "\n",
    "\n",
    "for mid, contexts in islice(texts.items(), 3):\n",
    "    mention_norm = data.mentions[mid]\n",
    "    vertex = data.vertices[mid2vid[mid]]\n",
    "\n",
    "    print(f'\\ntext for {mention_norm} ({mid=}) ({vertex=})')\n",
    "    for context in contexts:\n",
    "        wrapped = '\\n'.join(textwrap.wrap(str(context.data), 80),)\n",
    "        indented = textwrap.indent(wrapped, ' ' * 2)\n",
    "        print('\\n' + indented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60879c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can create a Graph instance from the dataset to look at the\n",
    "# training data a bit more closely\n",
    "\n",
    "from irt2.graph import Relation\n",
    "\n",
    "\n",
    "print(data.graph.description)\n",
    "\n",
    "relations = Relation.from_graph(data.graph)\n",
    "print(f'got {len(relations)} relations')\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def relation_table(relations):\n",
    "    headers = '#', 'name', 'rid', 'ratio', '#heads', '#tails', '#triples'\n",
    "    rows = []\n",
    "    for no, rel in enumerate(relations, 1):\n",
    "        rows.append((no, rel.name, rel.rid, rel.ratio, len(rel.heads), len(rel.tails), len(rel.triples)))\n",
    "\n",
    "    return tabulate(rows, headers=headers)\n",
    "\n",
    "\n",
    "print(relation_table(relations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "name": "load-dataset.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
